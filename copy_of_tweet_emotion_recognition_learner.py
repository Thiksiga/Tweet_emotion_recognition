# -*- coding: utf-8 -*-
"""Copy of Tweet Emotion Recognition - Learner.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GF4PryNy5b5LLxEJZYfPb_uS7P5_kfCb

## Tweet Emotion Recognition: Natural Language Processing with TensorFlow

---

Dataset: [Tweet Emotion Dataset](https://github.com/dair-ai/emotion_dataset)

This is a starter notebook for the guided project [Tweet Emotion Recognition with TensorFlow](https://www.coursera.org/projects/tweet-emotion-tensorflow)

A complete version of this notebook is available in the course resources

---

## Task 1: Introduction

## Task 2: Setup and Imports

1. Installing Hugging Face's nlp package
2. Importing libraries
"""

!pip install nlp

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import nlp
import random
import pandas as pd
import tensorflow as tf


def show_history(h):
    epochs_trained = len(h.history['loss'])
    plt.figure(figsize=(16, 6))

    plt.subplot(1, 2, 1)
    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')
    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')
    plt.ylim([0., 1.])
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')
    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()


def show_confusion_matrix(y_true, y_pred, classes):
    from sklearn.metrics import confusion_matrix

    cm = confusion_matrix(y_true, y_pred, normalize='true')

    plt.figure(figsize=(8, 8))
    sp = plt.subplot(1, 1, 1)
    ctx = sp.matshow(cm)
    plt.xticks(list(range(0, 6)), labels=classes)
    plt.yticks(list(range(0, 6)), labels=classes)
    plt.colorbar(ctx)
    plt.show()


print('Using TensorFlow version', tf.__version__)

"""## Task 3: Importing Data

1. Importing the Tweet Emotion dataset
2. Creating train, validation and test sets
3. Extracting tweets and labels from the examples
"""

pip install datasets

from datasets import load_dataset

dataset = load_dataset('emotion')

dataset

train=dataset['train']
valid=dataset['validation']
test=dataset['test']

dataframe = pd.DataFrame(train)

# Display the DataFrame
print(dataframe.head(10))

def get_tweet(data):
  tweets=[x['text'] for x in data]
  lables=[x['label'] for x in data]
  return tweets,lables

tweets,lables=get_tweet(train)

dat_fr=pd.DataFrame(tweets)
print(dat_fr.head())

tweets[2],lables[2]

"""## Task 4: Tokenizer

1. Tokenizing the tweets

(It means "we are representing the words in numbers" innorder to do data analysis, we need to input in numeical forms)
"""

from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer=Tokenizer(num_words=10000,oov_token='<UNK>')
tokenizer.fit_on_texts(tweets)

tokenizer.texts_to_sequences([tweets[0]])

"""## Task 5: Padding and Truncating Sequences

1. Checking length of the tweets
2. Creating padded sequences
"""

lengths=[len(t.split(" ")) for t in tweets]
plt.hist(lengths,bins=len(set(lengths)))
plt.show()

maxlen=50

from tensorflow.keras.preprocessing.sequence import pad_sequences

def get_sequences(tokenizer,tweets):
  sequences=tokenizer.texts_to_sequences(tweets)
  padded=pad_sequences(sequences,truncating='post',padding='post',maxlen=maxlen)
  return padded

padded_train_seq=get_sequences(tokenizer,tweets)

padded_train_seq[0]

"""## Task 6: Preparing the Labels

1. Creating classes to index and index to classes dictionaries
2. Converting text labels to numeric labels
***{Note: For our data set no need to create lables. because they are already in numerical form. for practice, we manually assigned text and recreated the numerical lables}***
"""

print(lables)

print(set(lables))

classes=set(lables)
print(classes)

emotions=['anger','joy','love','surprise','fear','sadness']

class_to_index=dict((c,i) for i, c in enumerate(emotions))
index_to_class=dict((v,k) for k, v in class_to_index.items())

class_to_index

index_to_class

names_to_ids=lambda lables: np.array([index_to_class.get(x) for x in lables])

train_lables=names_to_ids(lables)

print(train_lables[3])

"""## Task 7: Creating the Model

1. Creating the model
2. Compiling the model
"""

model=tf.keras.models.Sequential([
    tf.keras.layers.Embedding(10000,16,input_length=maxlen),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20,return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),
    tf.keras.layers.Dense(6,activation='softmax')
])

model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

"""## Task 8: Training the Model

1. Preparing a validation set
2. Training the model
"""

valid_tweets,valid_lables=get_tweet(valid)
valid_seq=get_sequences(tokenizer,valid_tweets)
#valid_lables=names_to_ids(valid_lables)

valid_tweets[0],valid_lables[0]

tf.version
!pip install --upgrade tensorflow

train_lables

valid_lables

import numpy as np

padded_train_seq = np.array(padded_train_seq)
train_labels = np.array(lables)
valid_seq = np.array(valid_seq)
valid_labels = np.array(valid_lables)

h=model.fit(padded_train_seq,train_labels,
            validation_data=(valid_seq,valid_labels),
            epochs=20,
            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=2)]
            )

train_lables

"""## Task 9: Evaluating the Model

1. Visualizing training history
2. Prepraring a test set
3. A look at individual predictions on the test set
4. A look at all predictions on the test set
"""

show_history(h)

test_tweets,test_lables=get_tweet(test)
test_seq=get_sequences(tokenizer,test_tweets)

test_labels = np.array(test_lables)
test_seq = np.array(test_seq)

_=model.evaluate(test_seq,test_labels)

i=random.randint(0,len(test_labels)-1)

print('Sentence:',test_tweets[i])
print('Emotion:',index_to_class[test_labels[i]])

p=model.predict(np.expand_dims(test_seq[i],axis=0))[0]
pred_class=index_to_class[np.argmax(p).astype('uint8')]

print('Predicted Emotion:',pred_class)

preds=model.predict(test_seq)

# Converting predicted probabilities to class labels
preds_class = np.argmax(preds, axis=1)

show_confusion_matrix(test_labels,preds_class,list(classes))

